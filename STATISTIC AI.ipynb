{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aec74f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#library imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns  \n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b52157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the dataset\n",
    "csv_path = r\"C:\\Users\\fedi\\Documents\\ESEN-HACK\\enhanced_pet_sales.csv\"\n",
    "df = pd.read_csv(csv_path, parse_dates=['order_date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb298fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick peek at the first few rows\n",
    "print(\" First 5 rows of raw data:\")\n",
    "print(df.head(), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe43ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'sales' is numeric; if not, coerce to NaN and fill with the column mean\n",
    "df['sales'] = pd.to_numeric(df['sales'], errors='coerce')\n",
    "df['sales'].fillna(df['sales'].mean(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6559596e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'price' is numeric; if not, coerce to NaN and fill with the column median\n",
    "df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "df['price'].fillna(df['price'].median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6864016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert boolean columns to integers (0 or 1)\n",
    "df['in_stock'] = df['in_stock'].astype(int)\n",
    "df['holiday_season'] = df['holiday_season'].astype(int)\n",
    "df['is_discounted'] = df['is_discounted'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c573c56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert other numeric-ish columns to numeric dtype, filling any missing values\n",
    "df['discount_pct'] = pd.to_numeric(df['discount_pct'], errors='coerce').fillna(0.0)\n",
    "df['avg_review_score'] = pd.to_numeric(df['avg_review_score'], errors='coerce').fillna(0.0)\n",
    "df['num_reviews'] = pd.to_numeric(df['num_reviews'], errors='coerce').fillna(0)\n",
    "df['stock_left'] = pd.to_numeric(df['stock_left'], errors='coerce').fillna(0)\n",
    "df['ad_spend'] = pd.to_numeric(df['ad_spend'], errors='coerce').fillna(0.0)\n",
    "df['click_through_rate'] = pd.to_numeric(df['click_through_rate'], errors='coerce').fillna(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3695dc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data after cleaning\n",
    "print(\">>> Data types after cleaning:\")\n",
    "print(df.dtypes, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2b7372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract \"month\" and \"weekday\" from the 'order_date' (we already parsed it above)\n",
    "df['month'] = df['order_date'].dt.month\n",
    "df['weekday'] = df['order_date'].dt.weekday"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e2244f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One‐Hot Encode categorical columns: 'animal_type' & 'category'\n",
    "#     After this, we get columns like 'animal_type_dog' (1 if dog, 0 if cat),\n",
    "#     plus 'category_Bed', 'category_Collar', etc.\n",
    "dummies = pd.get_dummies(df[['animal_type', 'category']], drop_first=True)\n",
    "df = pd.concat([df, dummies], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 Histogram of 'sales' \n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.histplot(df['sales'], bins=30, kde=True)\n",
    "plt.title(\"Distribution of Sales\")\n",
    "plt.xlabel(\"Sales (units)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"hist_sales.png\")\n",
    "plt.close()\n",
    "print(\"Saved plot → hist_sales.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a61d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Boxplot of 'price' by 'animal_type' to compare cat vs. dog pricing\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.boxplot(x='animal_type', y='price', data=df)\n",
    "plt.title(\"Price Distribution by Animal Type\")\n",
    "plt.xlabel(\"Animal Type\")\n",
    "plt.ylabel(\"Price (USD)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"boxplot_price_by_animal.png\")\n",
    "plt.close()\n",
    "print(\"Saved plot → boxplot_price_by_animal.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a53161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Correlation matrix (numeric + dummy columns)\n",
    "#      First collect a list of numeric & dummy columns:\n",
    "numeric_cols = [\n",
    "    'price', 'month', 'weekday',\n",
    "    'is_discounted', 'discount_pct',\n",
    "    'avg_review_score', 'num_reviews',\n",
    "    'in_stock', 'stock_left',\n",
    "    'ad_spend', 'click_through_rate',\n",
    "    'holiday_season'\n",
    "]\n",
    "dummy_cols = [col for col in df.columns if col.startswith('animal_type_') or col.startswith('category_')]\n",
    "all_corr_cols = numeric_cols + dummy_cols\n",
    "\n",
    "corr_matrix = df[all_corr_cols].corr()\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(\n",
    "    corr_matrix,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"viridis\",    \n",
    "    linewidths=0.5\n",
    ")\n",
    "plt.title(\"Feature Correlation Matrix\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"corr_matrix.png\")\n",
    "plt.close()\n",
    "print(\"Saved plot → corr_matrix.png\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33c5cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define features (X) and target (y)\n",
    "feature_cols = all_corr_cols\n",
    "X = df[feature_cols]\n",
    "y = df['sales']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ddb9245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check: make sure none of the feature columns are missing\n",
    "missing_cols = [col for col in feature_cols if col not in X.columns]\n",
    "if missing_cols:\n",
    "    raise ValueError(f\"Missing columns in X: {missing_cols}\")\n",
    "print(\"✅ All feature columns are present.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca70893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train (80%) and test (20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.20, random_state=42\n",
    ")\n",
    "print(f\"Training set size:  {X_train.shape[0]} rows\")\n",
    "print(f\"Testing set size:   {X_test.shape[0]} rows\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cf9f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MODEL SELECTION & HYPERPARAMETER TUNING (RANDOM FOREST)\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100],\n",
    "    'max_depth': [5, 10, None]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=rf,\n",
    "    param_grid=param_grid,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"Starting GridSearchCV for RandomForestRegressor...\")\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_forest = grid_search.best_estimator_\n",
    "print(\"✔︎ Best hyperparameters:\", grid_search.best_params_, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d1855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  EVALUATE ON TEST SET\n",
    "y_pred = best_forest.predict(X_test)\n",
    "\n",
    "mse_test = mean_squared_error(y_test, y_pred)\n",
    "r2_test = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MSE on test set:  {mse_test:.2f}\")\n",
    "print(f\"R² on test set:   {r2_test:.2f}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9960037f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  PLOT FEATURE IMPORTANCES (SEABORN BARPLOT)\n",
    "importances = best_forest.feature_importances_\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': feature_cols,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.barplot(\n",
    "    x='importance',\n",
    "    y='feature',\n",
    "    data=importance_df,\n",
    "    palette='magma'\n",
    ")\n",
    "plt.title(\"Feature Importances (Random Forest)\")\n",
    "plt.xlabel(\"Relative Importance\")\n",
    "plt.ylabel(\"Feature\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importances_rf.png\")\n",
    "plt.close()\n",
    "print(\"Saved plot → feature_importances_rf.png\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33877ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # PLOT ACTUAL VS. PREDICTED (SCATTER WITH SEABORN)\n",
    "plt.figure(figsize=(6, 6))\n",
    "sns.scatterplot(x=y_test, y=y_pred, alpha=0.6, edgecolor=None)\n",
    "plt.plot([y_test.min(), y_test.max()],\n",
    "         [y_test.min(), y_test.max()], 'k--')\n",
    "plt.title(\"Actual vs. Predicted Sales\")\n",
    "plt.xlabel(\"True Sales\")\n",
    "plt.ylabel(\"Predicted Sales\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"actual_vs_predicted_rf.png\")\n",
    "plt.close()\n",
    "print(\"Saved plot → actual_vs_predicted_rf.png\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a463631d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Serialize the trained model to disk\n",
    "model_filename = \"rf_sales_model.joblib\"\n",
    "joblib.dump(best_forest, model_filename)\n",
    "print(f\"✔︎ Saved trained model → {model_filename}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635710aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print top‐selling and lowest‐selling products (by true sales)\n",
    "top_idx = df['sales'].idxmax()\n",
    "worst_idx = df['sales'].idxmin()\n",
    "\n",
    "print(\" Top‐selling product (true sales):\")\n",
    "print(df.loc[top_idx, ['product_name', 'animal_type', 'category', 'sales']], \"\\n\")\n",
    "\n",
    "print(\"  Lowest‐selling product (true sales):\")\n",
    "print(df.loc[worst_idx, ['product_name', 'animal_type', 'category', 'sales']], \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
